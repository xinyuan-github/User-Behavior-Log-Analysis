# 1 对日志数据进行格式处理
- 将数据集中的 tab 符号更换为逗号
```bash
cat weblog.log|tr "\t" "," > weblog.log
```
- 将文件中的空格更换成逗号
```bash
cat weblog2.log|tr " " "," > weblog.log
```

# 2 自定义 SinkHBase 程序设计与开发
- 模仿 SimpleAsyncHbaseEventSerializer 自定义 KfkAsyncHbaseEventSerializer 实现类，修改一下代码即可
```java
@Override
public List<PutRequest> getActions() {
    List<PutRequest> actions = new ArrayList<PutRequest>();
    if (payloadColumn != null) {
         byte[] rowKey;
        try {
             /*---------------------------代码修改开始---------------------------------*/
            // 解析列字段
            String[] columns = new String(this.payloadColumn).split(",");
            // 解析flume采集过来的每行的值
            String[] values = new String(this.payload).split(",");
            for (int i = 0; i < columns.length; i++) {
                 byte[] colColumn = columns[i].getBytes();
                byte[] colValue = values[i].getBytes(Charsets.UTF_8);
    
                // 数据校验：字段和值是否对应
                if (colColumn.length != colValue.length) {
                    break;
                }
                // 时间
                String datetime = values[0].toString();
                // 用户id
                String userid = values[1].toString();
                // 根据业务自定义Rowkey
                rowKey = SimpleRowKeyGenerator.getKfkRowKey(userid, datetime);
                // 插入数据
                PutRequest putRequest =  new PutRequest(table, rowKey, cf,
                            colColumn, colValue);
                actions.add(putRequest);
            /*---------------------------代码修改结束---------------------------------*/
            }
    
        } catch (Exception e) {
                throw new FlumeException("Could not get row key!", e);
        }
    }
    return actions;
}
```

- 在 SimpleRowKeyGenerator 类中，根据具体业务自定义 Rowkey 生成方法
```java
public static byte[] getKfkRowKey(String userid, String datetime) throws UnsupportedEncodingException {
    return (userid + "-" + datetime + "-" + String.valueOf(System.currentTimeMillis())).getBytes("UTF8");
}
```

# 3 在 idea 开发工具中构建 weblogs 项目，编写数据生成模拟程序
```java
package main.java;
 
import java.io.*;
public class ReadWrite {
 
    static String readFileName;
    static String writeFileName;
 
    public static void main(String args[]){
        readFileName = args[0];
        writeFileName = args[1];
        try {
            // readInput();
            readFileByLines(readFileName);
        }catch(Exception e){
        }
    }
 
    public static void readFileByLines(String fileName) {
        FileInputStream fis = null;
        InputStreamReader isr = null;
        BufferedReader br = null;
        String tempString = null;
        try {
            System.out.println("以行为单位读取文件内容，一次读一整行：");
            fis = new FileInputStream(fileName);// FileInputStream
            // 从文件系统中的某个文件中获取字节
            isr = new InputStreamReader(fis, "GBK");
            br = new BufferedReader(isr);
            int count = 0;
            while ((tempString = br.readLine()) != null) {
                count++;
                // 显示行号
                Thread.sleep(300);
                String str = new String(tempString.getBytes("UTF8"), "GBK");
                System.out.println("row:" + count + ">>>>>>>>" + tempString);
                method1(writeFileName, tempString);
                //appendMethodA(writeFileName,tempString);
            }
            //关闭流
            isr.close();
        } catch (IOException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            //上面关闭流的时候如果抛异常了，则进行异常处理，处理完如果流还存在，则将其强制关闭
            if (isr != null) {
                try {
                    isr.close();
                } catch (IOException e1) {
                }
            }
        }
    }
 
    public static void method1(String file, String conent) {
        BufferedWriter out = null;
        try {
            out = new BufferedWriter(new OutputStreamWriter(
                    new FileOutputStream(file, true)));
            out.write("\n");
            out.write(conent);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            try {
                out.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
```

# 4 编写运行模拟程序的 shell 脚本
```bash
#/bin/bash
echo "start log......"
#第一个参数是原日志文件，第二个参数是日志生成输出文件
java -jar /opt/jars/weblogs.jar /opt/datas/weblog.log /opt/datas/weblog-flume.log
```

# 5 编写启动 flume 服务程序的 shell 脚本
在各节点的 flume 安装目录下编写 flume 启动脚本 flume-kfk-start.sh。下面是 node5 中的配置写法，node6 与 node7 中将 a1 分别改为 a2 和 a3。

```bash
#/bin/bash
echo "flume-1 start ......"
bin/flume-ng agent --conf conf -f conf/flume-conf.properties -n a1 -Dflume.root.logger=INFO,console
```

# 6 编写 Kafka Consumer 执行脚本 kfk-test-consumer.sh
```bash
#/bin/bash
echo "kfk-kafka-consumer.sh start......"
bin/kafka-console-consumer.sh --zookeeper node5:2181,node6:2181,node7:2181 --from-beginning --topic weblogs
```

# 7 启动 Kafka Consumer 查看 flume 日志采集情况
```bash
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic weblogs --from-beginning
```

